{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "page1=tk.Tk()\n",
    "page1.geometry('500x354')\n",
    "page1.title('Welcome To a Wonderful Page')\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "\n",
    "def resize(w, h, w_box, h_box, pil_image):  \n",
    "\n",
    "    f1 = 1.0*w_box/w \n",
    "    f2 = 1.0*h_box/h  \n",
    "    factor = min([f1, f2])  \n",
    "  \n",
    "    width = int(w*factor)  \n",
    "    height = int(h*factor)  \n",
    "    \n",
    "    return pil_image.resize((width, height),Image.ANTIALIAS)\n",
    "       \n",
    "def fp1():\n",
    "    page2 = tk.Tk()\n",
    "    page2.title('Type in')\n",
    "    page2.geometry('300x300')\n",
    "    tk.Label(page2,text=\"輸入關鍵字\",font=('Arial',21),bg='yellow').pack()\n",
    "    tk.Label(page2).pack()\n",
    "    tk.Label(page2,text='輸入文字',font=('Arial',12),bg='orange',width=10,height=1).pack()\n",
    "    keywords=tk.Entry(page2,show=None)\n",
    "    keywords.pack()\n",
    "    \n",
    "\n",
    "    \n",
    "    def fp3_1():\n",
    "        key=keywords.get()\n",
    "        \n",
    "        page2.destroy()  \n",
    "        page3 =tk.Tk()\n",
    "        page3.title('Please Make Gerenal Choice')\n",
    "        page3.geometry('300x300')\n",
    "        tk.Label(page3,text=\"您想做哪類的搜尋呢?\",font=('Arial',21),bg='pink').pack()\n",
    "        \n",
    "        def fp4_1():\n",
    "            page3.destroy()\n",
    "            page41=tk.Tk()\n",
    "            page41.geometry('300x300')\n",
    "            page41.title('Choose Browser')\n",
    "            tk.Label(page41,text='想使用哪種搜尋引擎',font=('Arial',21),bg='yellow').pack()\n",
    "            \n",
    "            def func2_1():\n",
    "                page51_1=tk.Tk()\n",
    "                page51_1.geometry('1000x500')\n",
    "                page51_1.title('Google')\n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    #FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "                                \n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                driver = FinalProject()\n",
    "                driver.google(key)\n",
    "                t = driver.dictionary['google']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page51_1)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        if y != None:\n",
    "                            o=list(y)\n",
    "                            if o[:9] != list(chec):\n",
    "                                if len(y)>80:\n",
    "                                    lb.insert(tk.END,y[:80])\n",
    "                                    lb.insert(tk.END,y[80:])\n",
    "                                else:    \n",
    "                                    lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                page51_1.mainloop()\n",
    "            cp41_1 = tk.Button(page41, text='Google',command=func2_1)\n",
    "            cp41_1.place(x = 96, y = 65 , width=120, height=25)\n",
    "            \n",
    "            def func2_2():\n",
    "                page51_2=tk.Tk()\n",
    "                page51_2.geometry('1000x500')\n",
    "                page51_2.title('Yahoo')\n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    #FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "                                \n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                driver = FinalProject()\n",
    "                driver.yahoo(key)\n",
    "                t = driver.dictionary['yahoo']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page51_2)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        if y != None:\n",
    "                            o=list(y)\n",
    "                            if o[:9] != list(chec):\n",
    "                                if len(y)>80:\n",
    "                                    lb.insert(tk.END,y[:80])\n",
    "                                    lb.insert(tk.END,y[80:])\n",
    "                                else:    \n",
    "                                    lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                page51_2.mainloop()\n",
    "            cp41_2 = tk.Button(page41, text='Yahoo', command=func2_2)\n",
    "            cp41_2.place(x = 96, y = 95 , width=120, height=25)\n",
    "            \n",
    "            def func2_3():\n",
    "                page51_3=tk.Tk()\n",
    "                page51_3.geometry('1000x500')\n",
    "                page51_3.title('Bing')\n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    #FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "                                \n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                driver = FinalProject()\n",
    "                driver.bing(key)\n",
    "                t = driver.dictionary['bing']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page51_3)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        if  y != None:\n",
    "                            o=list(y)\n",
    "                            if o[:9] != list(chec):\n",
    "                                if len(y)>80:\n",
    "                                    lb.insert(tk.END,y[:80])\n",
    "                                    lb.insert(tk.END,y[80:])\n",
    "                                else:    \n",
    "                                    lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                page51_3.mainloop()\n",
    "            cp41_3 = tk.Button(page41, text='Bing', command=func2_3)\n",
    "            cp41_3.place(x = 96, y = 125 , width=120, height=25)\n",
    "            \n",
    "\n",
    "                        \n",
    "                        \n",
    "            \n",
    "            page41.mainloop()\n",
    "            \n",
    "        c1 = tk.Button(page3, text='一般搜尋',font=('Arial',18),command=fp4_1)\n",
    "        c1.place(x = 100, y = 65 , width=120, height=25)\n",
    "        \n",
    "        def fp4_2():\n",
    "            page3.destroy()\n",
    "            page43=tk.Tk()\n",
    "            page43.geometry('1000x500')\n",
    "            page43.title('Youtube')\n",
    "            \n",
    "            from selenium import webdriver\n",
    "            from selenium.webdriver.support.wait import WebDriverWait\n",
    "            from selenium.webdriver.support import expected_conditions as EC\n",
    "            from selenium.webdriver.common.by import By\n",
    "            from selenium.webdriver.common.keys import Keys\n",
    "            from bs4 import BeautifulSoup\n",
    "\n",
    "            class FinalProject:\n",
    "\n",
    "                def __init__(self, headless = True):\n",
    "\n",
    "                    from selenium import webdriver\n",
    "\n",
    "                    option = webdriver.ChromeOptions()\n",
    "                    option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                    if headless:\n",
    "                        option.add_argument('--headless')       #隱藏頁面\n",
    "                    driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                    self.driver = driver    #設定好的driver\n",
    "                    self.set_dictionary()\n",
    "\n",
    "                def set_dictionary(self):\n",
    "                    self.dictionary = {}\n",
    "                    websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                    for website in websites:\n",
    "                        self.dictionary[website] = {}\n",
    "\n",
    "                def wait_and_find(self, by, path):\n",
    "                    locator = (by, path)\n",
    "                    WebDriverWait(self.driver, 30, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                    method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                    return method(path)\n",
    "\n",
    "                def wait_and_finds(self, by, path):\n",
    "                    locator = (by, path)\n",
    "                    WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                    method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                    return method(path)\n",
    "\n",
    "                @staticmethod\n",
    "                def print5(title, time, summary, link, picture):\n",
    "                    print(\"title: \",title)\n",
    "                    if time != None:\n",
    "                        print(\"time: \",time)\n",
    "                    if summary != None:\n",
    "                        print(\"summary:\",summary)\n",
    "                    print(\"link: \",link)\n",
    "                    print(\"picture: \", picture)\n",
    "                    print()\n",
    "\n",
    "                @staticmethod\n",
    "                def imagepath():\n",
    "\n",
    "                    import os\n",
    "                    from tkinter import filedialog\n",
    "\n",
    "                    default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                    fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                    return fname # 文件絕對路徑\n",
    "\n",
    "                @staticmethod\n",
    "                def path_is_image(path):\n",
    "\n",
    "                    import imghdr\n",
    "                    img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                    if img != None:\n",
    "                        return True\n",
    "                    return False \n",
    "\n",
    "                def google_image(self):\n",
    "\n",
    "                    imagepath = FinalProject.imagepath()\n",
    "                    while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                        print(\"請選擇一張圖片!!\")\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "\n",
    "                    #打開google圖片\n",
    "                    self.driver.get('https://www.google.com.tw/imghp')\n",
    "                    imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                    imagebutton.click()\n",
    "\n",
    "                    #傳送圖片\n",
    "                    image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                    image.send_keys(imagepath)\n",
    "\n",
    "                    #取得搜尋結果\n",
    "                    q = self.wait_and_find(By.NAME, \"q\")\n",
    "                    image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                    return image_response\n",
    "\n",
    "                def google_translate(self, image_response):\n",
    "\n",
    "                    #打開google翻譯並輸入文字\n",
    "                    self.driver.get('https://translate.google.com/')\n",
    "                    transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                    transinput.send_keys(image_response)\n",
    "\n",
    "                    #取得中文翻譯以及原文語言\n",
    "                    translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                    lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                    print()\n",
    "                    print(\"中文: \" + translate_response)\n",
    "                    print()\n",
    "\n",
    "                    #取得英文翻譯\n",
    "                    if lang == \"英文\":\n",
    "                        print(\"英文: \" + image_response)\n",
    "                    else:\n",
    "                        englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                        englishbutton.click()    #點擊英文翻譯\n",
    "                        english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                        print(\"英文: \" + english)\n",
    "\n",
    "                        if lang != \"中文\":\n",
    "                            #原文非中文,英文\n",
    "                            print(lang + \": \" + image_response)\n",
    "                    print()\n",
    "\n",
    "                    return translate_response\n",
    "\n",
    "                def wikipedia(self, translate_response):\n",
    "                    #查詢維基百科\n",
    "                    self.driver.get(\"https://www.google.com.tw/\")\n",
    "                    q = self.wait_and_find(By.NAME, \"q\")\n",
    "                    q.send_keys(translate_response+\" 維基百科\")\n",
    "                    q.send_keys(Keys.RETURN)\n",
    "\n",
    "                    #點擊第一項名字有維基百科的搜尋結果\n",
    "                    self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                    g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                    for title in g:\n",
    "                        if \"維基百科\" in title.text:\n",
    "                            title.click()\n",
    "                            break\n",
    "\n",
    "                    #找尋解釋文字\n",
    "                    wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                    print(wikitext)\n",
    "\n",
    "                    try:      \n",
    "                        disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                        if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                            #處理消歧義頁面問題 \n",
    "                            alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                            l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                            for i in range(l):\n",
    "                                print()\n",
    "                                disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                print(disambiguation_i_text)   #子頁面名稱\n",
    "                                disambiguation_i.click()\n",
    "\n",
    "                                #取得子頁面解釋\n",
    "                                subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                print(subtext)\n",
    "                                self.driver.back()\n",
    "                    except:\n",
    "                        #無消歧義\n",
    "                        pass\n",
    "                    print()\n",
    "\n",
    "                def cezisuanming(self, translate_response):\n",
    "\n",
    "                    #打開諸葛神數\n",
    "                    self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                    poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                    poeminput.send_keys(translate_response)     #輸入中文\n",
    "                    poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                    #取得籤詩及其解釋\n",
    "                    poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                    poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                    print(\"籤詩: \" + poem)\n",
    "                    print()\n",
    "                    print(poem_analysis)\n",
    "                    print()\n",
    "\n",
    "                def udn(self, search):\n",
    "                    if search in self.dictionary[\"udn\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://udn.com/search/result/2/\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"udn\"][search] = []\n",
    "                        soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                        for i in search_content:\n",
    "                            link = i.get(\"href\")\n",
    "                            title = i.find(\"h2\").text\n",
    "                            time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                            summary = i.find(\"p\").text\n",
    "                            picture = i.find(\"img\").get(\"src\")\n",
    "                            self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                def chinatimes(self, search):\n",
    "                    if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"chinatimes\"][search] = []\n",
    "                        soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                        for i in search_content:\n",
    "                            if i.get(\"id\") == None:\n",
    "                                h3 = i.find(\"h3\")\n",
    "                                title = h3.text\n",
    "                                a = h3.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                def tvbs(self, search):\n",
    "                    if search in self.dictionary[\"tvbs\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                        self.driver.get(html)        \n",
    "                        self.dictionary[\"tvbs\"][search] = []\n",
    "                        soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                        for i in search_content:\n",
    "                            a = i.find(\"a\")\n",
    "                            link = a.get(\"href\")\n",
    "                            title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                            time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                            picture = i.find(\"img\").get(\"src\")\n",
    "                            self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                            FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                def nownews(self, search):\n",
    "                    if search in self.dictionary[\"nownews\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"nownews\"][search] = []\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                        for i in search_content:\n",
    "                            gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                            title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                            temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                            time, summary = temp[0], temp[1]\n",
    "                            picture = i.find(\"img\").get(\"src\")\n",
    "                            self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                def ftvnews(self, search):\n",
    "                    if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"ftvnews\"][search] = []\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                        for i in search_content:\n",
    "                            link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                            time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                            title = i.find(\"div\", class_ = \"title\").text\n",
    "                            summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                            picture = i.find(\"img\").get(\"src\")\n",
    "                            self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                def apple(self, search):\n",
    "                    if search in self.dictionary[\"apple\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"apple\"][search] = []\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                        for i in search_content:\n",
    "                            a = i.find(\"a\")\n",
    "                            title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                            summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                            time = i.find(\"time\").text\n",
    "                            self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                            FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                def ltn(self, search):\n",
    "                    if search in self.dictionary[\"ltn\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"ltn\"][search] = []\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                        for i in search_content:\n",
    "                            time = i.find(\"span\").text\n",
    "                            a = i.find(\"a\", class_ = \"tit\")\n",
    "                            title, link = a.text, a.get(\"href\")\n",
    "                            summary = \"\".join(i.find(\"p\").text.split())\n",
    "                            picture = i.find(\"img\").get(\"src\")\n",
    "                            self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                            FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                def google(self, search):\n",
    "                    if search in self.dictionary[\"google\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://www.google.com/search?q=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"google\"][search] = []\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                        for i in search_content:\n",
    "                            try:\n",
    "                                h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                title = h3.text\n",
    "                                a = h3.find_parent(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                FinalProject.print5(title, None, summary, link, None)\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                def yahoo(self, search):\n",
    "                    if search in self.dictionary[\"yahoo\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"yahoo\"][search] = []\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                        for i in search_content:\n",
    "                            try:\n",
    "                                h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                title = h3.text\n",
    "                                link = h3.find(\"a\").get(\"href\")\n",
    "                                summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                FinalProject.print5(title, None, summary, link, None)\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                def youtube(self, search):\n",
    "                    if search in self.dictionary[\"youtube\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"youtube\"][search] = []\n",
    "                        self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "                        \n",
    "                        for i in search_content:\n",
    "                            a = i.find(\"a\", id = \"thumbnail\")\n",
    "                            link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                            picture = a.find(\"img\").get(\"src\")\n",
    "                            title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                            time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                            summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                            self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                            #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                def bing(self, search):\n",
    "                    if search in self.dictionary[\"bing\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://www.bing.com/search?q=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"bing\"][search] = []\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                        for i in search_content:\n",
    "                            try:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                FinalProject.print5(title, None, summary, link, None)\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "            def CallOn(event):\n",
    "                chec2='http'\n",
    "                it = list(lb.get(lb.curselection()))\n",
    "                if it[:4] == list(chec2):\n",
    "                    url = lb.get(lb.curselection())\n",
    "                    browser = webdriver.Chrome()\n",
    "                    browser.set_window_size(900, 900)  \n",
    "                    browser.get(url)\n",
    "                else:\n",
    "                    pass\n",
    "            driver = FinalProject()\n",
    "            driver.youtube(key)\n",
    "            t = driver.dictionary['youtube']\n",
    "            s=t[key]\n",
    "            r=0\n",
    "            lb = tk.Listbox(page43)\n",
    "            lb.bind('<Double-Button-1>',CallOn)\n",
    "            for i in s:\n",
    "                i=list(i)\n",
    "                i.pop(-1)\n",
    "                for y in i:\n",
    "\n",
    "                    chec='https://i'\n",
    "                    o=list(y)\n",
    "                    if o[:9] != list(chec):\n",
    "                        if len(y)>80:\n",
    "                            lb.insert(tk.END,y[:80])\n",
    "                            lb.insert(tk.END,y[80:])\n",
    "                        else:    \n",
    "                            lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "            lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "            \n",
    "            page43.mainloop()\n",
    "        c2 = tk.Button(page3, text='影片搜尋',font=('Arial',18),command=fp4_2)\n",
    "        c2.place(x = 100, y = 95 , width=120, height=25)\n",
    "        \n",
    "        def fp4_3():\n",
    "            page3.destroy()\n",
    "            page42=tk.Tk()\n",
    "            page42.geometry('700x700')\n",
    "            page42.title('Choose News')\n",
    "            tk.Label(page42, text='請選擇想要的新聞', bg='pink') .pack()\n",
    "            \n",
    "\n",
    "            \n",
    "            def func1():\n",
    "                page52_1=tk.Tk()\n",
    "                page52_1.geometry('1000x500')\n",
    "                page52_1.title(\"UDN\")\n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "                \n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                driver = FinalProject()\n",
    "                driver.udn(key)\n",
    "                t = driver.dictionary['udn']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page52_1)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        o=list(y)\n",
    "                        if o[:9] != list(chec):\n",
    "                            if len(y)>80:\n",
    "                                lb.insert(tk.END,y[:80])\n",
    "                                lb.insert(tk.END,y[80:])\n",
    "                            else:    \n",
    "                                lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                \n",
    "                page52_1.mainloop()\n",
    "\n",
    "            c1 = tk.Button(page42, text='UDN', command=func1)\n",
    "            c1.place(x = 293, y = 30 , width=120, height=25)\n",
    "            \n",
    "            def func2():\n",
    "                page52_2=tk.Tk()\n",
    "                page52_2.geometry('1000x500')\n",
    "                page52_2.title(\"ChinaTimes\")\n",
    "                \n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                \n",
    "                driver = FinalProject()\n",
    "                driver.chinatimes(key)\n",
    "                t = driver.dictionary['chinatimes']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page52_2)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        o=list(y)\n",
    "                        if o[:9] != list(chec):\n",
    "                            if len(y)>80:\n",
    "                                lb.insert(tk.END,y[:80])\n",
    "                                lb.insert(tk.END,y[80:])\n",
    "                            else:    \n",
    "                                lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                    \n",
    "                page52_2.mainloop()\n",
    "            c2 = tk.Button(page42, text='ChinaTimes',command=func2)\n",
    "            c2.place(x = 293, y = 60 , width=120, height=25)\n",
    "            \n",
    "            def func3():\n",
    "                page52_3=tk.Tk()\n",
    "                page52_3.geometry('1000x500')\n",
    "                page52_3.title(\"TVBS\")\n",
    "                \n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                            \n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                #FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                driver = FinalProject()\n",
    "                driver.tvbs(key)\n",
    "                t = driver.dictionary['tvbs']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page52_3)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        if y != None :\n",
    "                            o = list(y)\n",
    "                            if o[:9] != list(chec) :\n",
    "                                if len(y)>80:\n",
    "                                    lb.insert(tk.END,y[:80])\n",
    "                                    lb.insert(tk.END,y[80:])\n",
    "                                else:    \n",
    "                                    lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                    \n",
    "                page52_3.mainloop()\n",
    "            c3 = tk.Button(page42, text='TVBS', command=func3)\n",
    "            c3.place(x = 293, y = 90 , width=120, height=25)\n",
    "            \n",
    "            def func4():\n",
    "                page52_4=tk.Tk()\n",
    "                page52_4.geometry('1000x500')\n",
    "                page52_4.title(\"Now News\")\n",
    "                \n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "               \n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                \n",
    "                driver = FinalProject()\n",
    "                driver.nownews(key)\n",
    "                t = driver.dictionary['nownews']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page52_4)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        o=list(y)\n",
    "                        if o[:9] != list(chec) :\n",
    "                            if len(y)>80:\n",
    "                                lb.insert(tk.END,y[:80])\n",
    "                                lb.insert(tk.END,y[80:])\n",
    "                            else:    \n",
    "                                lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                page52_4.mainloop()\n",
    "            c4 = tk.Button(page42, text='Now News', command=func4)\n",
    "            c4.place(x = 293, y = 120 , width=120, height=25)\n",
    "            \n",
    "            def func5():\n",
    "                page52_5=tk.Tk()\n",
    "                page52_5.geometry('1000x500')\n",
    "                page52_5.title(\"Ftv News\")\n",
    "                \n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "                \n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                driver = FinalProject()\n",
    "                driver.ftvnews(key)\n",
    "                t = driver.dictionary['ftvnews']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page52_5)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        o=list(y)\n",
    "                        if o[:9] != list(chec):\n",
    "                            if len(y)>80:\n",
    "                                lb.insert(tk.END,y[:80])\n",
    "                                lb.insert(tk.END,y[80:])\n",
    "                            else:    \n",
    "                                lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                    \n",
    "                page52_5.mainloop()\n",
    "            c5 = tk.Button(page42, text='Ftv News', command=func5)\n",
    "            c5.place(x = 293, y = 150 , width=120, height=25)\n",
    "            \n",
    "            def func6():\n",
    "                page52_6=tk.Tk()\n",
    "                page52_6.geometry('1000x500')\n",
    "                page52_6.title(\"Apple News\")\n",
    "\n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                #FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "                \n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                driver = FinalProject()\n",
    "                driver.apple(key)\n",
    "                t = driver.dictionary['apple']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page52_6)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        o=list(y)\n",
    "                        if o[:9] != list(chec):\n",
    "                            if len(y)>80:\n",
    "                                lb.insert(tk.END,y[:80])\n",
    "                                lb.insert(tk.END,y[80:])\n",
    "                            else:    \n",
    "                                lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                    \n",
    "                page52_6.mainloop()\n",
    "            c6 = tk.Button(page42, text='Apple News', command=func6)\n",
    "            c6.place(x = 293, y = 180 , width=120, height=25)\n",
    "            \n",
    "            def func7():\n",
    "                page52_7=tk.Tk()\n",
    "                page52_7.geometry('1000x500')\n",
    "                page52_7.title(\"LTN\")\n",
    "                \n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = None\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                #FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                driver = FinalProject()\n",
    "                driver.ltn(key)\n",
    "                t = driver.dictionary['ltn']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page52_7)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        o=list(y)\n",
    "                        if o[:9] != list(chec):\n",
    "                            if len(y)>80:\n",
    "                                lb.insert(tk.END,y[:80])\n",
    "                                lb.insert(tk.END,y[80:])\n",
    "                            else:    \n",
    "                                lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                page52_7.mainloop()\n",
    "            c7 = tk.Button(page42, text='LTN', command=func7)\n",
    "            c7.place(x = 293, y = 210 , width=120, height=25)\n",
    "            \n",
    "            \n",
    "                        \n",
    "                        \n",
    "            \n",
    "            page42.mainloop()\n",
    "            \n",
    "            \n",
    "        c3 = tk.Button(page3, text='新聞搜尋',font=('Arial',18),command=fp4_3)\n",
    "        c3.place(x = 100, y = 125 , width=120, height=25)\n",
    "        \n",
    "        \n",
    "        page3.mainloop()\n",
    "        \n",
    "\n",
    "   \n",
    "        \n",
    "    tk.Button(page2,text='查詢',command=fp3_1).pack()\n",
    "    tk.Label(page2).pack()\n",
    "    \n",
    "    def fp3_2():\n",
    "        \n",
    "        from selenium import webdriver\n",
    "        from selenium.webdriver.support.wait import WebDriverWait\n",
    "        from selenium.webdriver.support import expected_conditions as EC\n",
    "        from selenium.webdriver.common.by import By\n",
    "        from selenium.webdriver.common.keys import Keys\n",
    "        from bs4 import BeautifulSoup\n",
    "\n",
    "        class FinalProject:\n",
    "\n",
    "            def __init__(self, headless = True):\n",
    "\n",
    "                from selenium import webdriver\n",
    "\n",
    "                option = webdriver.ChromeOptions()\n",
    "                option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                if headless:\n",
    "                    option.add_argument('--headless')       #隱藏頁面\n",
    "                driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                self.driver = driver    #設定好的driver\n",
    "                self.set_dictionary()\n",
    "\n",
    "            def set_dictionary(self):\n",
    "                self.dictionary = {}\n",
    "                websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                for website in websites:\n",
    "                    self.dictionary[website] = {}\n",
    "\n",
    "            def wait_and_find(self, by, path):\n",
    "                locator = (by, path)\n",
    "                WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                return method(path)\n",
    "\n",
    "            def wait_and_finds(self, by, path):\n",
    "                locator = (by, path)\n",
    "                WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                return method(path)\n",
    "\n",
    "            @staticmethod\n",
    "            def print5(title, time, summary, link, picture):\n",
    "                print(\"title: \",title)\n",
    "                if time != None:\n",
    "                    print(\"time: \",time)\n",
    "                if summary != None:\n",
    "                    print(\"summary:\",summary)\n",
    "                print(\"link: \",link)\n",
    "                print(\"picture: \", picture)\n",
    "                print()\n",
    "\n",
    "            @staticmethod\n",
    "            def imagepath():\n",
    "\n",
    "                import os\n",
    "                from tkinter import filedialog\n",
    "\n",
    "                default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "            \n",
    "                return fname # 文件絕對路徑\n",
    "\n",
    "            @staticmethod\n",
    "            def path_is_image(path):\n",
    "\n",
    "                import imghdr\n",
    "                img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                if img != None:\n",
    "                    return True\n",
    "                return False \n",
    "\n",
    "            def google_image(self):\n",
    "\n",
    "                imagepath = FinalProject.imagepath()\n",
    "                #while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                 #   print(\"請選擇一張圖片!!\")\n",
    "                  #  imagepath = FinalProject.imagepath()\n",
    "\n",
    "                #打開google圖片\n",
    "                self.driver.get('https://www.google.com.tw/imghp')\n",
    "                imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                imagebutton.click()\n",
    "\n",
    "                #傳送圖片\n",
    "                image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                image.send_keys(imagepath)\n",
    "\n",
    "                #取得搜尋結果\n",
    "                q = self.wait_and_find(By.NAME, \"q\")\n",
    "                image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                return image_response\n",
    "\n",
    "            def google_translate(self, image_response):\n",
    "\n",
    "                #打開google翻譯並輸入文字\n",
    "                self.driver.get('https://translate.google.com/')\n",
    "                transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                transinput.send_keys(image_response)\n",
    "\n",
    "                #取得中文翻譯以及原文語言\n",
    "                translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                #print()\n",
    "                #print(\"中文: \" + translate_response)\n",
    "                #print()\n",
    "\n",
    "                #取得英文翻譯\n",
    "\n",
    "\n",
    "                return translate_response\n",
    "\n",
    "            def wikipedia(self, translate_response):\n",
    "                #查詢維基百科\n",
    "                self.driver.get(\"https://www.google.com.tw/\")\n",
    "                q = self.wait_and_find(By.NAME, \"q\")\n",
    "                q.send_keys(translate_response+\" 維基百科\")\n",
    "                q.send_keys(Keys.RETURN)\n",
    "\n",
    "                #點擊第一項名字有維基百科的搜尋結果\n",
    "                self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                for title in g:\n",
    "                    if \"維基百科\" in title.text:\n",
    "                        title.click()\n",
    "                        break\n",
    "\n",
    "                #找尋解釋文字\n",
    "                wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                print(wikitext)\n",
    "\n",
    "                try:      \n",
    "                    disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                    if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                        #處理消歧義頁面問題 \n",
    "                        alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                        l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                        for i in range(l):\n",
    "                            print()\n",
    "                            disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                            disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                            print(disambiguation_i_text)   #子頁面名稱\n",
    "                            disambiguation_i.click()\n",
    "\n",
    "                            #取得子頁面解釋\n",
    "                            subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                            print(subtext)\n",
    "                            self.driver.back()\n",
    "                except:\n",
    "                    #無消歧義\n",
    "                    pass\n",
    "                print()\n",
    "\n",
    "            def cezisuanming(self, translate_response):\n",
    "\n",
    "                #打開諸葛神數\n",
    "                self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                poeminput.send_keys(translate_response)     #輸入中文\n",
    "                poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                #取得籤詩及其解釋\n",
    "                poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                print(\"籤詩: \" + poem)\n",
    "                print()\n",
    "                print(poem_analysis)\n",
    "                print()\n",
    "\n",
    "            def udn(self, search):\n",
    "                if search in self.dictionary[\"udn\"].keys():\n",
    "                    for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                        FinalProject.print5(title, time, summary, link, picture)\n",
    "                else:\n",
    "                    html = \"https://udn.com/search/result/2/\" + search\n",
    "                    self.driver.get(html)\n",
    "                    self.dictionary[\"udn\"][search] = []\n",
    "                    soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                    search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                    for i in search_content:\n",
    "                        link = i.get(\"href\")\n",
    "                        title = i.find(\"h2\").text\n",
    "                        time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                        summary = i.find(\"p\").text\n",
    "                        picture = i.find(\"img\").get(\"src\")\n",
    "                        self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                        #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "            def chinatimes(self, search):\n",
    "                if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                    for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                        FinalProject.print5(title, time, summary, link, picture)\n",
    "                else:\n",
    "                    html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                    self.driver.get(html)\n",
    "                    self.dictionary[\"chinatimes\"][search] = []\n",
    "                    soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                    search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                    for i in search_content:\n",
    "                        if i.get(\"id\") == None:\n",
    "                            h3 = i.find(\"h3\")\n",
    "                            title = h3.text\n",
    "                            a = h3.find(\"a\")\n",
    "                            link = a.get(\"href\")\n",
    "                            time_list = i.find(\"time\").find_all(\"span\")\n",
    "                            time = time_list[0].text + \" \" + time_list[1].text\n",
    "                            summary = i.find(\"p\").text\n",
    "                            picture = i.find(\"img\").get(\"src\")\n",
    "                            self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "            def tvbs(self, search):\n",
    "                if search in self.dictionary[\"tvbs\"].keys():\n",
    "                    for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                        FinalProject.print5(title, time, summary, link, picture)\n",
    "                else:\n",
    "                    html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                    self.driver.get(html)        \n",
    "                    self.dictionary[\"tvbs\"][search] = []\n",
    "                    soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                    search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                    for i in search_content:\n",
    "                        a = i.find(\"a\")\n",
    "                        link = a.get(\"href\")\n",
    "                        title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                        time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                        picture = i.find(\"img\").get(\"src\")\n",
    "                        self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                        FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "            def nownews(self, search):\n",
    "                if search in self.dictionary[\"nownews\"].keys():\n",
    "                    for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                        FinalProject.print5(title, time, summary, link, picture)\n",
    "                else:\n",
    "                    html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                    self.driver.get(html)\n",
    "                    self.dictionary[\"nownews\"][search] = []\n",
    "                    soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                    search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                    for i in search_content:\n",
    "                        gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                        title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                        temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                        time, summary = temp[0], temp[1]\n",
    "                        picture = i.find(\"img\").get(\"src\")\n",
    "                        self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                        FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "            def ftvnews(self, search):\n",
    "                if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                    for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                        FinalProject.print5(title, time, summary, link, picture)\n",
    "                else:\n",
    "                    html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                    self.driver.get(html)\n",
    "                    self.dictionary[\"ftvnews\"][search] = []\n",
    "                    soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                    search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                    for i in search_content:\n",
    "                        link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                        time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                        title = i.find(\"div\", class_ = \"title\").text\n",
    "                        summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                        picture = i.find(\"img\").get(\"src\")\n",
    "                        self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                        FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "            def apple(self, search):\n",
    "                if search in self.dictionary[\"apple\"].keys():\n",
    "                    for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                        FinalProject.print5(title, time, summary, link, picture)\n",
    "                else:\n",
    "                    html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                    self.driver.get(html)\n",
    "                    self.dictionary[\"apple\"][search] = []\n",
    "                    soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                    search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                    for i in search_content:\n",
    "                        a = i.find(\"a\")\n",
    "                        title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                        summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                        time = i.find(\"time\").text\n",
    "                        self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                        FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "            def ltn(self, search):\n",
    "                if search in self.dictionary[\"ltn\"].keys():\n",
    "                    for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                        FinalProject.print5(title, time, summary, link, picture)\n",
    "                else:\n",
    "                    html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                    self.driver.get(html)\n",
    "                    self.dictionary[\"ltn\"][search] = []\n",
    "                    soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                    search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                    for i in search_content:\n",
    "                        time = i.find(\"span\").text\n",
    "                        a = i.find(\"a\", class_ = \"tit\")\n",
    "                        title, link = a.text, a.get(\"href\")\n",
    "                        summary = \"\".join(i.find(\"p\").text.split())\n",
    "                        picture = i.find(\"img\").get(\"src\")\n",
    "                        self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                        FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "            def google(self, search):\n",
    "                if search in self.dictionary[\"google\"].keys():\n",
    "                    for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                        FinalProject.print5(title, time, summary, link, picture)\n",
    "                else:\n",
    "                    html = \"https://www.google.com/search?q=\" + search\n",
    "                    self.driver.get(html)\n",
    "                    self.dictionary[\"google\"][search] = []\n",
    "                    soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                    search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                    for i in search_content:\n",
    "                        try:\n",
    "                            h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                            title = h3.text\n",
    "                            a = h3.find_parent(\"a\")\n",
    "                            link = a.get(\"href\")\n",
    "                            summary = i.find(\"span\", class_ = \"st\").text\n",
    "                            self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                            #FinalProject.print5(title, None, summary, link, None)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "            def yahoo(self, search):\n",
    "                if search in self.dictionary[\"yahoo\"].keys():\n",
    "                    for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                        FinalProject.print5(title, time, summary, link, picture)\n",
    "                else:\n",
    "                    html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                    self.driver.get(html)\n",
    "                    self.dictionary[\"yahoo\"][search] = []\n",
    "                    soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                    search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                    for i in search_content:\n",
    "                        try:\n",
    "                            h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                            title = h3.text\n",
    "                            link = h3.find(\"a\").get(\"href\")\n",
    "                            summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                            self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                            FinalProject.print5(title, None, summary, link, None)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "            def youtube(self, search):\n",
    "                if search in self.dictionary[\"youtube\"].keys():\n",
    "                    for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                        FinalProject.print5(title, time, summary, link, picture)\n",
    "                else:\n",
    "                    html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                    self.driver.get(html)\n",
    "                    self.dictionary[\"youtube\"][search] = []\n",
    "                    self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                    soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                    search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                    for i in search_content:\n",
    "                        a = i.find(\"a\", id = \"thumbnail\")\n",
    "                        link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                        picture = a.find(\"img\").get(\"src\")\n",
    "                        title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                        time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                        summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                        self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                        #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "            def bing(self, search):\n",
    "                if search in self.dictionary[\"bing\"].keys():\n",
    "                    for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                        FinalProject.print5(title, time, summary, link, picture)\n",
    "                else:\n",
    "                    html = \"https://www.bing.com/search?q=\" + search\n",
    "                    self.driver.get(html)\n",
    "                    self.dictionary[\"bing\"][search] = []\n",
    "                    soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                    search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                    for i in search_content:\n",
    "                        try:\n",
    "                            a = i.find(\"a\")\n",
    "                            title, link = a.text, a.get(\"href\")\n",
    "                            summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                            self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                            FinalProject.print5(title, None, summary, link, None)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "        driver=FinalProject()\n",
    "        keywords=driver.google_image()\n",
    "        key=driver.google_translate(keywords)\n",
    "        \n",
    "        page2.destroy()  \n",
    "        page3 =tk.Tk()\n",
    "        page3.title('Please Make Gerenal Choice')\n",
    "        page3.geometry('300x300')\n",
    "        tk.Label(page3,text=\"您想做哪類的搜尋呢?\",font=('Arial',21),bg='pink').pack()\n",
    "        \n",
    "        def fp4_1():\n",
    "            page3.destroy()\n",
    "            page41=tk.Tk()\n",
    "            page41.geometry('300x300')\n",
    "            page41.title('Choose Browser')\n",
    "            tk.Label(page41,text='想使用哪種搜尋引擎',font=('Arial',21),bg='yellow').pack()\n",
    "            \n",
    "            def func2_1():\n",
    "                page51_1=tk.Tk()\n",
    "                page51_1.geometry('1000x500')\n",
    "                page51_1.title('Google')\n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    #FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "                                \n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                driver = FinalProject()\n",
    "                driver.google(key)\n",
    "                t = driver.dictionary['google']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page51_1)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        if y != None:\n",
    "                            o=list(y)\n",
    "                            if o[:9] != list(chec):\n",
    "                                if len(y)>80:\n",
    "                                    lb.insert(tk.END,y[:80])\n",
    "                                    lb.insert(tk.END,y[80:])\n",
    "                                else:    \n",
    "                                    lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                page51_1.mainloop()\n",
    "            cp41_1 = tk.Button(page41, text='Google',command=func2_1)\n",
    "            cp41_1.place(x = 96, y = 65 , width=120, height=25)\n",
    "            \n",
    "            def func2_2():\n",
    "                page51_2=tk.Tk()\n",
    "                page51_2.geometry('1000x500')\n",
    "                page51_2.title('Yahoo')\n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    #FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "                                \n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                driver = FinalProject()\n",
    "                driver.yahoo(key)\n",
    "                t = driver.dictionary['yahoo']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page51_2)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        if y != None:\n",
    "                            o=list(y)\n",
    "                            if o[:9] != list(chec):\n",
    "                                if len(y)>80:\n",
    "                                    lb.insert(tk.END,y[:80])\n",
    "                                    lb.insert(tk.END,y[80:])\n",
    "                                else:    \n",
    "                                    lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                page51_2.mainloop()\n",
    "            cp41_2 = tk.Button(page41, text='Yahoo', command=func2_2)\n",
    "            cp41_2.place(x = 96, y = 95 , width=120, height=25)\n",
    "            \n",
    "            def func2_3():\n",
    "                page51_3=tk.Tk()\n",
    "                page51_3.geometry('1000x500')\n",
    "                page51_3.title('Bing')\n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    #FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "                                \n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                driver = FinalProject()\n",
    "                driver.bing(key)\n",
    "                t = driver.dictionary['bing']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page51_3)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        if  y != None:\n",
    "                            o=list(y)\n",
    "                            if o[:9] != list(chec):\n",
    "                                if len(y)>80:\n",
    "                                    lb.insert(tk.END,y[:80])\n",
    "                                    lb.insert(tk.END,y[80:])\n",
    "                                else:    \n",
    "                                    lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                page51_3.mainloop()\n",
    "            cp41_3 = tk.Button(page41, text='Bing', command=func2_3)\n",
    "            cp41_3.place(x = 96, y = 125 , width=120, height=25)\n",
    "            \n",
    "\n",
    "                        \n",
    "                        \n",
    "            \n",
    "            page41.mainloop()\n",
    "            \n",
    "        c1 = tk.Button(page3, text='一般搜尋',font=('Arial',18),command=fp4_1)\n",
    "        c1.place(x = 100, y = 65 , width=120, height=25)\n",
    "        \n",
    "        def fp4_2():\n",
    "            page3.destroy()\n",
    "            page43=tk.Tk()\n",
    "            page43.geometry('1000x500')\n",
    "            page43.title('Youtube')\n",
    "            \n",
    "            from selenium import webdriver\n",
    "            from selenium.webdriver.support.wait import WebDriverWait\n",
    "            from selenium.webdriver.support import expected_conditions as EC\n",
    "            from selenium.webdriver.common.by import By\n",
    "            from selenium.webdriver.common.keys import Keys\n",
    "            from bs4 import BeautifulSoup\n",
    "\n",
    "            class FinalProject:\n",
    "\n",
    "                def __init__(self, headless = True):\n",
    "\n",
    "                    from selenium import webdriver\n",
    "\n",
    "                    option = webdriver.ChromeOptions()\n",
    "                    option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                    if headless:\n",
    "                        option.add_argument('--headless')       #隱藏頁面\n",
    "                    driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                    self.driver = driver    #設定好的driver\n",
    "                    self.set_dictionary()\n",
    "\n",
    "                def set_dictionary(self):\n",
    "                    self.dictionary = {}\n",
    "                    websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                    for website in websites:\n",
    "                        self.dictionary[website] = {}\n",
    "\n",
    "                def wait_and_find(self, by, path):\n",
    "                    locator = (by, path)\n",
    "                    WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                    method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                    return method(path)\n",
    "\n",
    "                def wait_and_finds(self, by, path):\n",
    "                    locator = (by, path)\n",
    "                    WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                    method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                    return method(path)\n",
    "\n",
    "                @staticmethod\n",
    "                def print5(title, time, summary, link, picture):\n",
    "                    print(\"title: \",title)\n",
    "                    if time != None:\n",
    "                        print(\"time: \",time)\n",
    "                    if summary != None:\n",
    "                        print(\"summary:\",summary)\n",
    "                    print(\"link: \",link)\n",
    "                    print(\"picture: \", picture)\n",
    "                    print()\n",
    "\n",
    "                @staticmethod\n",
    "                def imagepath():\n",
    "\n",
    "                    import os\n",
    "                    from tkinter import filedialog\n",
    "\n",
    "                    default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                    fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                    return fname # 文件絕對路徑\n",
    "\n",
    "                @staticmethod\n",
    "                def path_is_image(path):\n",
    "\n",
    "                    import imghdr\n",
    "                    img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                    if img != None:\n",
    "                        return True\n",
    "                    return False \n",
    "\n",
    "                def google_image(self):\n",
    "\n",
    "                    imagepath = FinalProject.imagepath()\n",
    "                    while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                        print(\"請選擇一張圖片!!\")\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "\n",
    "                    #打開google圖片\n",
    "                    self.driver.get('https://www.google.com.tw/imghp')\n",
    "                    imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                    imagebutton.click()\n",
    "\n",
    "                    #傳送圖片\n",
    "                    image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                    image.send_keys(imagepath)\n",
    "\n",
    "                    #取得搜尋結果\n",
    "                    q = self.wait_and_find(By.NAME, \"q\")\n",
    "                    image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                    return image_response\n",
    "\n",
    "                def google_translate(self, image_response):\n",
    "\n",
    "                    #打開google翻譯並輸入文字\n",
    "                    self.driver.get('https://translate.google.com/')\n",
    "                    transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                    transinput.send_keys(image_response)\n",
    "\n",
    "                    #取得中文翻譯以及原文語言\n",
    "                    translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                    lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                    print()\n",
    "                    print(\"中文: \" + translate_response)\n",
    "                    print()\n",
    "\n",
    "                    #取得英文翻譯\n",
    "                    if lang == \"英文\":\n",
    "                        print(\"英文: \" + image_response)\n",
    "                    else:\n",
    "                        englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                        englishbutton.click()    #點擊英文翻譯\n",
    "                        english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                        print(\"英文: \" + english)\n",
    "\n",
    "                        if lang != \"中文\":\n",
    "                            #原文非中文,英文\n",
    "                            print(lang + \": \" + image_response)\n",
    "                    print()\n",
    "\n",
    "                    return translate_response\n",
    "\n",
    "                def wikipedia(self, translate_response):\n",
    "                    #查詢維基百科\n",
    "                    self.driver.get(\"https://www.google.com.tw/\")\n",
    "                    q = self.wait_and_find(By.NAME, \"q\")\n",
    "                    q.send_keys(translate_response+\" 維基百科\")\n",
    "                    q.send_keys(Keys.RETURN)\n",
    "\n",
    "                    #點擊第一項名字有維基百科的搜尋結果\n",
    "                    self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                    g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                    for title in g:\n",
    "                        if \"維基百科\" in title.text:\n",
    "                            title.click()\n",
    "                            break\n",
    "\n",
    "                    #找尋解釋文字\n",
    "                    wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                    print(wikitext)\n",
    "\n",
    "                    try:      \n",
    "                        disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                        if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                            #處理消歧義頁面問題 \n",
    "                            alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                            l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                            for i in range(l):\n",
    "                                print()\n",
    "                                disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                print(disambiguation_i_text)   #子頁面名稱\n",
    "                                disambiguation_i.click()\n",
    "\n",
    "                                #取得子頁面解釋\n",
    "                                subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                print(subtext)\n",
    "                                self.driver.back()\n",
    "                    except:\n",
    "                        #無消歧義\n",
    "                        pass\n",
    "                    print()\n",
    "\n",
    "                def cezisuanming(self, translate_response):\n",
    "\n",
    "                    #打開諸葛神數\n",
    "                    self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                    poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                    poeminput.send_keys(translate_response)     #輸入中文\n",
    "                    poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                    #取得籤詩及其解釋\n",
    "                    poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                    poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                    print(\"籤詩: \" + poem)\n",
    "                    print()\n",
    "                    print(poem_analysis)\n",
    "                    print()\n",
    "\n",
    "                def udn(self, search):\n",
    "                    if search in self.dictionary[\"udn\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://udn.com/search/result/2/\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"udn\"][search] = []\n",
    "                        soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                        for i in search_content:\n",
    "                            link = i.get(\"href\")\n",
    "                            title = i.find(\"h2\").text\n",
    "                            time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                            summary = i.find(\"p\").text\n",
    "                            picture = i.find(\"img\").get(\"src\")\n",
    "                            self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                def chinatimes(self, search):\n",
    "                    if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"chinatimes\"][search] = []\n",
    "                        soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                        for i in search_content:\n",
    "                            if i.get(\"id\") == None:\n",
    "                                h3 = i.find(\"h3\")\n",
    "                                title = h3.text\n",
    "                                a = h3.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                def tvbs(self, search):\n",
    "                    if search in self.dictionary[\"tvbs\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                        self.driver.get(html)        \n",
    "                        self.dictionary[\"tvbs\"][search] = []\n",
    "                        soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                        for i in search_content:\n",
    "                            a = i.find(\"a\")\n",
    "                            link = a.get(\"href\")\n",
    "                            title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                            time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                            picture = i.find(\"img\").get(\"src\")\n",
    "                            self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                            FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                def nownews(self, search):\n",
    "                    if search in self.dictionary[\"nownews\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"nownews\"][search] = []\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                        for i in search_content:\n",
    "                            gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                            title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                            temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                            time, summary = temp[0], temp[1]\n",
    "                            picture = i.find(\"img\").get(\"src\")\n",
    "                            self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                def ftvnews(self, search):\n",
    "                    if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"ftvnews\"][search] = []\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                        for i in search_content:\n",
    "                            link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                            time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                            title = i.find(\"div\", class_ = \"title\").text\n",
    "                            summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                            picture = i.find(\"img\").get(\"src\")\n",
    "                            self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                def apple(self, search):\n",
    "                    if search in self.dictionary[\"apple\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"apple\"][search] = []\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                        for i in search_content:\n",
    "                            a = i.find(\"a\")\n",
    "                            title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                            summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                            time = i.find(\"time\").text\n",
    "                            self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                            FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                def ltn(self, search):\n",
    "                    if search in self.dictionary[\"ltn\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"ltn\"][search] = []\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                        for i in search_content:\n",
    "                            time = i.find(\"span\").text\n",
    "                            a = i.find(\"a\", class_ = \"tit\")\n",
    "                            title, link = a.text, a.get(\"href\")\n",
    "                            summary = \"\".join(i.find(\"p\").text.split())\n",
    "                            picture = i.find(\"img\").get(\"src\")\n",
    "                            self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                            FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                def google(self, search):\n",
    "                    if search in self.dictionary[\"google\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://www.google.com/search?q=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"google\"][search] = []\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                        for i in search_content:\n",
    "                            try:\n",
    "                                h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                title = h3.text\n",
    "                                a = h3.find_parent(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                FinalProject.print5(title, None, summary, link, None)\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                def yahoo(self, search):\n",
    "                    if search in self.dictionary[\"yahoo\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"yahoo\"][search] = []\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                        for i in search_content:\n",
    "                            try:\n",
    "                                h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                title = h3.text\n",
    "                                link = h3.find(\"a\").get(\"href\")\n",
    "                                summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                FinalProject.print5(title, None, summary, link, None)\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                def youtube(self, search):\n",
    "                    if search in self.dictionary[\"youtube\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"youtube\"][search] = []\n",
    "                        self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                        for i in search_content:\n",
    "                            a = i.find(\"a\", id = \"thumbnail\")\n",
    "                            link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                            picture = a.find(\"img\").get(\"src\")\n",
    "                            title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                            time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                            summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                            self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                            #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                def bing(self, search):\n",
    "                    if search in self.dictionary[\"bing\"].keys():\n",
    "                        for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                            FinalProject.print5(title, time, summary, link, picture)\n",
    "                    else:\n",
    "                        html = \"https://www.bing.com/search?q=\" + search\n",
    "                        self.driver.get(html)\n",
    "                        self.dictionary[\"bing\"][search] = []\n",
    "                        soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                        search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                        for i in search_content:\n",
    "                            try:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                FinalProject.print5(title, None, summary, link, None)\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "            def CallOn(event):\n",
    "                chec2='http'\n",
    "                it = list(lb.get(lb.curselection()))\n",
    "                if it[:4] == list(chec2):\n",
    "                    url = lb.get(lb.curselection())\n",
    "                    browser = webdriver.Chrome()\n",
    "                    browser.set_window_size(900, 900)  \n",
    "                    browser.get(url)\n",
    "                else:\n",
    "                    pass\n",
    "            driver = FinalProject()\n",
    "            driver.youtube(key)\n",
    "            t = driver.dictionary['youtube']\n",
    "            s=t[key]\n",
    "            r=0\n",
    "            lb = tk.Listbox(page43)\n",
    "            lb.bind('<Double-Button-1>',CallOn)\n",
    "            for i in s:\n",
    "                i=list(i)\n",
    "                i.pop(-1)\n",
    "                for y in i:\n",
    "\n",
    "                    chec='https://i'\n",
    "                    o=list(y)\n",
    "                    if o[:9] != list(chec):\n",
    "                        if len(y)>80:\n",
    "                            lb.insert(tk.END,y[:80])\n",
    "                            lb.insert(tk.END,y[80:])\n",
    "                        else:    \n",
    "                            lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "            lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "            \n",
    "            page43.mainloop()\n",
    "        c2 = tk.Button(page3, text='影片搜尋',font=('Arial',18),command=fp4_2)\n",
    "        c2.place(x = 100, y = 95 , width=120, height=25)\n",
    "        \n",
    "        def fp4_3():\n",
    "            page3.destroy()\n",
    "            page42=tk.Tk()\n",
    "            page42.geometry('700x700')\n",
    "            page42.title('Choose News')\n",
    "            tk.Label(page42, text='請選擇想要的新聞', bg='pink') .pack()\n",
    "            \n",
    "\n",
    "            \n",
    "            def func1():\n",
    "                page52_1=tk.Tk()\n",
    "                page52_1.geometry('1000x500')\n",
    "                page52_1.title(\"UDN\")\n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "                \n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                driver = FinalProject()\n",
    "                driver.udn(key)\n",
    "                t = driver.dictionary['udn']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page52_1)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        o=list(y)\n",
    "                        if o[:9] != list(chec):\n",
    "                            if len(y)>80:\n",
    "                                lb.insert(tk.END,y[:80])\n",
    "                                lb.insert(tk.END,y[80:])\n",
    "                            else:    \n",
    "                                lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                \n",
    "                page52_1.mainloop()\n",
    "\n",
    "            c1 = tk.Button(page42, text='UDN', command=func1)\n",
    "            c1.place(x = 293, y = 30 , width=120, height=25)\n",
    "            \n",
    "            def func2():\n",
    "                page52_2=tk.Tk()\n",
    "                page52_2.geometry('1000x500')\n",
    "                page52_2.title(\"ChinaTimes\")\n",
    "                \n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                \n",
    "                driver = FinalProject()\n",
    "                driver.chinatimes(key)\n",
    "                t = driver.dictionary['chinatimes']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page52_2)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        o=list(y)\n",
    "                        if o[:9] != list(chec):\n",
    "                            if len(y)>80:\n",
    "                                lb.insert(tk.END,y[:80])\n",
    "                                lb.insert(tk.END,y[80:])\n",
    "                            else:    \n",
    "                                lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                    \n",
    "                page52_2.mainloop()\n",
    "            c2 = tk.Button(page42, text='ChinaTimes',command=func2)\n",
    "            c2.place(x = 293, y = 60 , width=120, height=25)\n",
    "            \n",
    "            def func3():\n",
    "                page52_3=tk.Tk()\n",
    "                page52_3.geometry('1000x500')\n",
    "                page52_3.title(\"TVBS\")\n",
    "                \n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                            \n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                #FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                driver = FinalProject()\n",
    "                driver.tvbs(key)\n",
    "                t = driver.dictionary['tvbs']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page52_3)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        if y != None :\n",
    "                            o = list(y)\n",
    "                            if o[:9] != list(chec) :\n",
    "                                if len(y)>80:\n",
    "                                    lb.insert(tk.END,y[:80])\n",
    "                                    lb.insert(tk.END,y[80:])\n",
    "                                else:    \n",
    "                                    lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                    \n",
    "                page52_3.mainloop()\n",
    "            c3 = tk.Button(page42, text='TVBS', command=func3)\n",
    "            c3.place(x = 293, y = 90 , width=120, height=25)\n",
    "            \n",
    "            def func4():\n",
    "                page52_4=tk.Tk()\n",
    "                page52_4.geometry('1000x500')\n",
    "                page52_4.title(\"Now News\")\n",
    "                \n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "               \n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                \n",
    "                driver = FinalProject()\n",
    "                driver.nownews(key)\n",
    "                t = driver.dictionary['nownews']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page52_4)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        o=list(y)\n",
    "                        if o[:9] != list(chec) :\n",
    "                            if len(y)>80:\n",
    "                                lb.insert(tk.END,y[:80])\n",
    "                                lb.insert(tk.END,y[80:])\n",
    "                            else:    \n",
    "                                lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                page52_4.mainloop()\n",
    "            c4 = tk.Button(page42, text='Now News', command=func4)\n",
    "            c4.place(x = 293, y = 120 , width=120, height=25)\n",
    "            \n",
    "            def func5():\n",
    "                page52_5=tk.Tk()\n",
    "                page52_5.geometry('1000x500')\n",
    "                page52_5.title(\"Ftv News\")\n",
    "                \n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "                \n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "                driver = FinalProject()\n",
    "                driver.ftvnews(key)\n",
    "                t = driver.dictionary['ftvnews']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page52_5)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        o=list(y)\n",
    "                        if o[:9] != list(chec):\n",
    "                            if len(y)>80:\n",
    "                                lb.insert(tk.END,y[:80])\n",
    "                                lb.insert(tk.END,y[80:])\n",
    "                            else:    \n",
    "                                lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                    \n",
    "                page52_5.mainloop()\n",
    "            c5 = tk.Button(page42, text='Ftv News', command=func5)\n",
    "            c5.place(x = 293, y = 150 , width=120, height=25)\n",
    "            \n",
    "            def func6():\n",
    "                page52_6=tk.Tk()\n",
    "                page52_6.geometry('1000x500')\n",
    "                page52_6.title(\"Apple News\")\n",
    "\n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                #FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "                \n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                driver = FinalProject()\n",
    "                driver.apple(key)\n",
    "                t = driver.dictionary['apple']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page52_6)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        o=list(y)\n",
    "                        if o[:9] != list(chec):\n",
    "                            if len(y)>80:\n",
    "                                lb.insert(tk.END,y[:80])\n",
    "                                lb.insert(tk.END,y[80:])\n",
    "                            else:    \n",
    "                                lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                    \n",
    "                page52_6.mainloop()\n",
    "            c6 = tk.Button(page42, text='Apple News', command=func6)\n",
    "            c6.place(x = 293, y = 180 , width=120, height=25)\n",
    "            \n",
    "            def func7():\n",
    "                page52_7=tk.Tk()\n",
    "                page52_7.geometry('1000x500')\n",
    "                page52_7.title(\"LTN\")\n",
    "                \n",
    "                from selenium import webdriver\n",
    "                from selenium.webdriver.support.wait import WebDriverWait\n",
    "                from selenium.webdriver.support import expected_conditions as EC\n",
    "                from selenium.webdriver.common.by import By\n",
    "                from selenium.webdriver.common.keys import Keys\n",
    "                from bs4 import BeautifulSoup\n",
    "\n",
    "                class FinalProject:\n",
    "\n",
    "                    def __init__(self, headless = True):\n",
    "\n",
    "                        from selenium import webdriver\n",
    "\n",
    "                        option = webdriver.ChromeOptions()\n",
    "                        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "                        if headless:\n",
    "                            option.add_argument('--headless')       #隱藏頁面\n",
    "                        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "                        self.driver = driver    #設定好的driver\n",
    "                        self.set_dictionary()\n",
    "\n",
    "                    def set_dictionary(self):\n",
    "                        self.dictionary = {}\n",
    "                        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "                        for website in websites:\n",
    "                            self.dictionary[website] = {}\n",
    "\n",
    "                    def wait_and_find(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "                        return method(path)\n",
    "\n",
    "                    def wait_and_finds(self, by, path):\n",
    "                        locator = (by, path)\n",
    "                        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "                        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "                        return method(path)\n",
    "\n",
    "                    @staticmethod\n",
    "                    def print5(title, time, summary, link, picture):\n",
    "                        print(\"title: \",title)\n",
    "                        if time != None:\n",
    "                            print(\"time: \",time)\n",
    "                        if summary != None:\n",
    "                            print(\"summary:\",summary)\n",
    "                        print(\"link: \",link)\n",
    "                        print(\"picture: \", picture)\n",
    "                        print()\n",
    "\n",
    "                    @staticmethod\n",
    "                    def imagepath():\n",
    "\n",
    "                        import os\n",
    "                        from tkinter import filedialog\n",
    "\n",
    "                        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "                        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "                        return fname # 文件絕對路徑\n",
    "\n",
    "                    @staticmethod\n",
    "                    def path_is_image(path):\n",
    "\n",
    "                        import imghdr\n",
    "                        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "                        if img != None:\n",
    "                            return True\n",
    "                        return False \n",
    "\n",
    "                    def google_image(self):\n",
    "\n",
    "                        imagepath = FinalProject.imagepath()\n",
    "                        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "                            print(\"請選擇一張圖片!!\")\n",
    "                            imagepath = FinalProject.imagepath()\n",
    "\n",
    "                        #打開google圖片\n",
    "                        self.driver.get('https://www.google.com.tw/imghp')\n",
    "                        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "                        imagebutton.click()\n",
    "\n",
    "                        #傳送圖片\n",
    "                        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "                        image.send_keys(imagepath)\n",
    "\n",
    "                        #取得搜尋結果\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "                        return image_response\n",
    "\n",
    "                    def google_translate(self, image_response):\n",
    "\n",
    "                        #打開google翻譯並輸入文字\n",
    "                        self.driver.get('https://translate.google.com/')\n",
    "                        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "                        transinput.send_keys(image_response)\n",
    "\n",
    "                        #取得中文翻譯以及原文語言\n",
    "                        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "                        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "                        print()\n",
    "                        print(\"中文: \" + translate_response)\n",
    "                        print()\n",
    "\n",
    "                        #取得英文翻譯\n",
    "                        if lang == \"英文\":\n",
    "                            print(\"英文: \" + image_response)\n",
    "                        else:\n",
    "                            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "                            englishbutton.click()    #點擊英文翻譯\n",
    "                            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "                            print(\"英文: \" + english)\n",
    "\n",
    "                            if lang != \"中文\":\n",
    "                                #原文非中文,英文\n",
    "                                print(lang + \": \" + image_response)\n",
    "                        print()\n",
    "\n",
    "                        return translate_response\n",
    "\n",
    "                    def wikipedia(self, translate_response):\n",
    "                        #查詢維基百科\n",
    "                        self.driver.get(\"https://www.google.com.tw/\")\n",
    "                        q = self.wait_and_find(By.NAME, \"q\")\n",
    "                        q.send_keys(translate_response+\" 維基百科\")\n",
    "                        q.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #點擊第一項名字有維基百科的搜尋結果\n",
    "                        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "                        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "                        for title in g:\n",
    "                            if \"維基百科\" in title.text:\n",
    "                                title.click()\n",
    "                                break\n",
    "\n",
    "                        #找尋解釋文字\n",
    "                        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                        print(wikitext)\n",
    "\n",
    "                        try:      \n",
    "                            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "                            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                                #處理消歧義頁面問題 \n",
    "                                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                                for i in range(l):\n",
    "                                    print()\n",
    "                                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                                    disambiguation_i.click()\n",
    "\n",
    "                                    #取得子頁面解釋\n",
    "                                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                                    print(subtext)\n",
    "                                    self.driver.back()\n",
    "                        except:\n",
    "                            #無消歧義\n",
    "                            pass\n",
    "                        print()\n",
    "\n",
    "                    def cezisuanming(self, translate_response):\n",
    "\n",
    "                        #打開諸葛神數\n",
    "                        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "                        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "                        poeminput.send_keys(translate_response)     #輸入中文\n",
    "                        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "                        #取得籤詩及其解釋\n",
    "                        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "                        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "                        print(\"籤詩: \" + poem)\n",
    "                        print()\n",
    "                        print(poem_analysis)\n",
    "                        print()\n",
    "\n",
    "                    def udn(self, search):\n",
    "                        if search in self.dictionary[\"udn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://udn.com/search/result/2/\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"udn\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "                            for i in search_content:\n",
    "                                link = i.get(\"href\")\n",
    "                                title = i.find(\"h2\").text\n",
    "                                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                                summary = i.find(\"p\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def chinatimes(self, search):\n",
    "                        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"chinatimes\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                if i.get(\"id\") == None:\n",
    "                                    h3 = i.find(\"h3\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                                    summary = i.find(\"p\").text\n",
    "                                    picture = i.find(\"img\").get(\"src\")\n",
    "                                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                                    FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def tvbs(self, search):\n",
    "                        if search in self.dictionary[\"tvbs\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "                            self.driver.get(html)        \n",
    "                            self.dictionary[\"tvbs\"][search] = []\n",
    "                            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                link = a.get(\"href\")\n",
    "                                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                                FinalProject.print5(title, time, None, link, picture)\n",
    "\n",
    "                    def nownews(self, search):\n",
    "                        if search in self.dictionary[\"nownews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"nownews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "                            for i in search_content:\n",
    "                                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                                time, summary = temp[0], temp[1]\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def ftvnews(self, search):\n",
    "                        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ftvnews\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                                title = i.find(\"div\", class_ = \"title\").text\n",
    "                                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                                picture = i.find(\"img\").get(\"src\")\n",
    "                                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "                    def apple(self, search):\n",
    "                        if search in self.dictionary[\"apple\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"apple\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\")\n",
    "                                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                                time = i.find(\"time\").text\n",
    "                                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                                FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def ltn(self, search):\n",
    "                        if search in self.dictionary[\"ltn\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"ltn\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                time = i.find(\"span\").text\n",
    "                                a = i.find(\"a\", class_ = \"tit\")\n",
    "                                title, link = a.text, a.get(\"href\")\n",
    "                                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                                picture = None\n",
    "                                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                                #FinalProject.print5(title, time, summary, link, None)\n",
    "\n",
    "                    def google(self, search):\n",
    "                        if search in self.dictionary[\"google\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.google.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"google\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                                    title = h3.text\n",
    "                                    a = h3.find_parent(\"a\")\n",
    "                                    link = a.get(\"href\")\n",
    "                                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def yahoo(self, search):\n",
    "                        if search in self.dictionary[\"yahoo\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"yahoo\"][search] = []\n",
    "                            \n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                                    title = h3.text\n",
    "                                    link = h3.find(\"a\").get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    def youtube(self, search):\n",
    "                        if search in self.dictionary[\"youtube\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"youtube\"][search] = []\n",
    "                            self.wait_and_find(By.CLASS_NAME,\"style-scope ytd-item-section-renderer\")\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find_all(\"ytd-video-renderer\")\n",
    "\n",
    "                            for i in search_content:\n",
    "                                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                                picture = a.find(\"img\").get(\"src\")\n",
    "                                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                                #FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "\n",
    "                    def bing(self, search):\n",
    "                        if search in self.dictionary[\"bing\"].keys():\n",
    "                            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                                FinalProject.print5(title, time, summary, link, picture)\n",
    "                        else:\n",
    "                            html = \"https://www.bing.com/search?q=\" + search\n",
    "                            self.driver.get(html)\n",
    "                            self.dictionary[\"bing\"][search] = []\n",
    "                            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "                            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "                            for i in search_content:\n",
    "                                try:\n",
    "                                    a = i.find(\"a\")\n",
    "                                    title, link = a.text, a.get(\"href\")\n",
    "                                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                                    FinalProject.print5(title, None, summary, link, None)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                def CallOn(event):\n",
    "                    chec2='http'\n",
    "                    it = list(lb.get(lb.curselection()))\n",
    "                    if it[:4] == list(chec2):\n",
    "                        url = lb.get(lb.curselection())\n",
    "                        browser = webdriver.Chrome()\n",
    "                        browser.set_window_size(900, 900)  \n",
    "                        browser.get(url)\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                driver = FinalProject()\n",
    "                driver.ltn(key)\n",
    "                t = driver.dictionary['ltn']\n",
    "                s=t[key]\n",
    "                r=0\n",
    "                lb = tk.Listbox(page52_7)\n",
    "                lb.bind('<Double-Button-1>',CallOn)\n",
    "                for i in s:\n",
    "                    i=list(i)\n",
    "                    i.pop(-1)\n",
    "                    for y in i:\n",
    "\n",
    "                        chec='https://i'\n",
    "                        o=list(y)\n",
    "                        if o[:9] != list(chec):\n",
    "                            if len(y)>80:\n",
    "                                lb.insert(tk.END,y[:80])\n",
    "                                lb.insert(tk.END,y[80:])\n",
    "                            else:    \n",
    "                                lb.insert(tk.END,y)\n",
    "\n",
    "\n",
    "                    lb.insert(tk.END,'------------------------------------------')\n",
    "\n",
    "                lb.pack(side=tk.LEFT, fill=tk.BOTH, expand=tk.YES) \n",
    "                page52_7.mainloop()\n",
    "            c7 = tk.Button(page42, text='LTN', command=func7)\n",
    "            c7.place(x = 293, y = 210 , width=120, height=25)\n",
    "            \n",
    "            \n",
    "                        \n",
    "                        \n",
    "            \n",
    "            page42.mainloop()\n",
    "            \n",
    "            \n",
    "        c3 = tk.Button(page3, text='新聞搜尋',font=('Arial',18),command=fp4_3)\n",
    "        c3.place(x = 100, y = 125 , width=120, height=25)\n",
    "        \n",
    "        \n",
    "        page3.mainloop()\n",
    "    \n",
    "    tk.Label(page2).pack()\n",
    "    tk.Button(page2,text=\"輸入圖片\",font=('Arial',12),bg='orange',width=10,height=1,command=fp3_2).pack()\n",
    "    \n",
    "\n",
    "\n",
    "    def fp2():\n",
    "        page3 = tk.Tk()\n",
    "        page3.title('Type in')\n",
    "        page2.geometry('300x300')\n",
    "        tk.Label(page3,text=\"輸入關鍵字\")        \n",
    "    \n",
    "    \n",
    "def fp1_2():\n",
    "    page1.destroy()\n",
    "    try:\n",
    "        page2.detroy()\n",
    "        page3.destroy()\n",
    "    except:\n",
    "        pass\n",
    "         \n",
    "imagepil = Image.open('final.png')\n",
    "t , u = imagepil.size\n",
    "imagech = resize(t,u,500,500,imagepil)\n",
    "imagetk = ImageTk.PhotoImage(imagech)\n",
    "p1p = tk.Label(page1,image=imagetk ,width = 500,height = 354)\n",
    "tk.Button(page1,text='Start',bg='yellow',font=('Arial',24),command=fp1).place(x = 35, y = 150 ,width=180,height=50)\n",
    "tk.Button(page1,text='Quit',bg='yellow',font=('Arial',24),command=fp1_2).place(x = 35, y = 265 ,width=180,height=50)\n",
    "\n",
    "\n",
    "p1p.pack()\n",
    "page1.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
